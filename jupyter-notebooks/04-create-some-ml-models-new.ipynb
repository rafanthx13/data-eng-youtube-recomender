{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ML Model\n",
    "\n",
    "## Entrada\n",
    "\n",
    "Arquivo com todas as label preenchdidas eplas etapas anteriores\n",
    "\n",
    "## Quando se faz Hyper-turning\n",
    "\n",
    "√â somente depois de tentar v√°rias possibildiades com os mdelos. O hyper-turning n√¢o faz milagre, entao s√≥ deixa pro final.\n",
    "\n",
    "## Descri√ß√¢o das aulas\n",
    "\n",
    "31 - Inicio do Notebook e testando hyer-turning no RandomForest\n",
    "\n",
    "32 - LightGBM e Sua hyperturning\n",
    "+ As formas de fazer hipertuning s√£o:\n",
    "   - GridSearhc: AL√©m de demorada n√¢o tem bons resultados pois √© manual e nao sabemos at√© que potnao estamos atingindo um bom valor o hiper-parametro que causae uma mudan√ßa positiva\n",
    "   - RandomSearch: Tende a ser melhor que GridSearch\n",
    "   - Baysean Optimization (AutoML): Uma nova abordagem que vamos usar nesse notebook.\n",
    "     * √â uma busca alert√≥ria mas guiada de forma inteligente\n",
    "     \n",
    "33 - Logistic Regression\n",
    "+ Vamos aprender como analisar as nossa features para a regres√£o logistica\n",
    "  - Aprensetou bons resultados\n",
    "  \n",
    "### Tabela de Score\n",
    "````\n",
    "RandomForest\n",
    " avg_precision :: 0.3876787322730141 ; roc_auc :: 0.6775564963329557\n",
    "LightGBM - No Hyper-Tuning\n",
    " avg_precision :: 0.358824358569258  ; roc_auc :: 0.644678313755888\n",
    "LightBGM com Baysian Optimizer\n",
    "'avg_precision': 0.40242103560963294 ; 'roc': 0.6723749329199212, \n",
    "Logistic REgression = C=0.5 StandardScaler\n",
    "(0.41578009994342235, 0.6897143879315486) -  \n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:32:36.213003Z",
     "start_time": "2021-12-23T15:32:03.601553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "pd.set_option(\"max.columns\", None)\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar e analisar DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:32:57.702909Z",
     "start_time": "2021-12-23T15:32:57.627736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1655, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_videos_dataset_manual_labeled_tabulation.tsv\", index_col=0, sep=\"\\t\").dropna(subset=['interesting'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T16:44:16.566504Z",
     "start_time": "2021-12-23T16:44:16.266931Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:33:04.898830Z",
     "start_time": "2021-12-23T15:33:04.846110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uploader</th>\n",
       "      <th>title</th>\n",
       "      <th>interesting</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>user</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>channel_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AltexSoft</td>\n",
       "      <td>How Data Engineering Works</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>AltexSoftChannel</td>\n",
       "      <td>70764</td>\n",
       "      <td>4014</td>\n",
       "      <td>https://i.ytimg.com/vi/qWru-b6m030/maxresdefau...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>data engineering|data science|data infrastruct...</td>\n",
       "      <td>https://www.youtube.com/channel/UCEKI_F16hUtBH...</td>\n",
       "      <td>So, the sole purpose of data engineering is to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uploader                       title  interesting upload_date  \\\n",
       "number                                                                   \n",
       "0       AltexSoft  How Data Engineering Works            1  2021-03-17   \n",
       "\n",
       "                    user  view_count  like_count  \\\n",
       "number                                             \n",
       "0       AltexSoftChannel       70764        4014   \n",
       "\n",
       "                                                thumbnail  width  height  \\\n",
       "number                                                                     \n",
       "0       https://i.ytimg.com/vi/qWru-b6m030/maxresdefau...   1920    1080   \n",
       "\n",
       "                  categories  \\\n",
       "number                         \n",
       "0       Science & Technology   \n",
       "\n",
       "                                                     tags  \\\n",
       "number                                                      \n",
       "0       data engineering|data science|data infrastruct...   \n",
       "\n",
       "                                              channel_url  \\\n",
       "number                                                      \n",
       "0       https://www.youtube.com/channel/UCEKI_F16hUtBH...   \n",
       "\n",
       "                                              description  \n",
       "number                                                     \n",
       "0       So, the sole purpose of data engineering is to...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:34:10.467313Z",
     "start_time": "2021-12-23T15:34:10.380422Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1358\n",
       "1     297\n",
       "Name: interesting, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['interesting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:34:54.997326Z",
     "start_time": "2021-12-23T15:34:54.987563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isnull()\n",
    "df['interesting'].value_counts().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:34:59.598184Z",
     "start_time": "2021-12-23T15:34:59.468401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sem duplicata\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:35:01.418709Z",
     "start_time": "2021-12-23T15:35:01.384538Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sem duplicata nos titulos\n",
    "df.duplicated(['title']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:35:46.644756Z",
     "start_time": "2021-12-23T15:35:46.595943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1645, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(['title'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:36:42.485264Z",
     "start_time": "2021-12-23T15:36:42.450063Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-b804edafa167>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['interesting'] = df['interesting'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "df['interesting'] = df['interesting'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:36:47.060522Z",
     "start_time": "2021-12-23T15:36:47.041000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1645 entries, 0 to 1660\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   uploader     1645 non-null   object \n",
      " 1   title        1645 non-null   object \n",
      " 2   interesting  1645 non-null   float64\n",
      " 3   upload_date  1645 non-null   object \n",
      " 4   user         1645 non-null   object \n",
      " 5   view_count   1645 non-null   int64  \n",
      " 6   like_count   1645 non-null   int64  \n",
      " 7   thumbnail    1645 non-null   object \n",
      " 8   width        1645 non-null   int64  \n",
      " 9   height       1645 non-null   int64  \n",
      " 10  categories   1645 non-null   object \n",
      " 11  tags         1207 non-null   object \n",
      " 12  channel_url  1645 non-null   object \n",
      " 13  description  1558 non-null   object \n",
      "dtypes: float64(1), int64(4), object(9)\n",
      "memory usage: 192.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:36:50.316368Z",
     "start_time": "2021-12-23T15:36:50.257789Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uploader</th>\n",
       "      <th>title</th>\n",
       "      <th>interesting</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>user</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>channel_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AltexSoft</td>\n",
       "      <td>How Data Engineering Works</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>AltexSoftChannel</td>\n",
       "      <td>70764</td>\n",
       "      <td>4014</td>\n",
       "      <td>https://i.ytimg.com/vi/qWru-b6m030/maxresdefau...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>data engineering|data science|data infrastruct...</td>\n",
       "      <td>https://www.youtube.com/channel/UCEKI_F16hUtBH...</td>\n",
       "      <td>So, the sole purpose of data engineering is to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seja Um Data Scientist</td>\n",
       "      <td>[Parte 01] Como √© o Trabalho de um Data Engine...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>UCar5Cr-pVz08GY_6I3RX9bA</td>\n",
       "      <td>11125</td>\n",
       "      <td>814</td>\n",
       "      <td>https://i.ytimg.com/vi_webp/nQu6s8FPhfA/maxres...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>data engineer|engenheiro de dados o que faz|fo...</td>\n",
       "      <td>https://www.youtube.com/channel/UCar5Cr-pVz08G...</td>\n",
       "      <td>Nesse v√≠deo, eu vou mostrar qual o papel de um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>Data Engineering Road Map - How To Learn Data ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>48598</td>\n",
       "      <td>2561</td>\n",
       "      <td>https://i.ytimg.com/vi_webp/SpaFPPByOhM/maxres...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Education</td>\n",
       "      <td>big data|data analytics|tableau|sql|big query|...</td>\n",
       "      <td>https://www.youtube.com/channel/UCmLGJ3VYBcfRa...</td>\n",
       "      <td>How do you go from 0 to data engineer?  What i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joma Tech</td>\n",
       "      <td>Data Scientists vs Data Engineers: Which one i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>UCV0qA-eDDICsRR9rPcnG7tw</td>\n",
       "      <td>246236</td>\n",
       "      <td>6683</td>\n",
       "      <td>https://i.ytimg.com/vi/vmYaAzbv9xk/maxresdefau...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Education</td>\n",
       "      <td>joma|vlog|data scientist|data science|data eng...</td>\n",
       "      <td>https://www.youtube.com/channel/UCV0qA-eDDICsR...</td>\n",
       "      <td>üìö Video courses from JomaClass: üéì New to progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>What Skills Do Data Engineers Need To Know</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>33370</td>\n",
       "      <td>1870</td>\n",
       "      <td>https://i.ytimg.com/vi/LgSHaOvNodA/maxresdefau...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Education</td>\n",
       "      <td>big data|data analytics|tableau|sql|big query|...</td>\n",
       "      <td>https://www.youtube.com/channel/UCmLGJ3VYBcfRa...</td>\n",
       "      <td>Learn More about data engineering Googles DE c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      uploader  \\\n",
       "number                           \n",
       "0                    AltexSoft   \n",
       "1       Seja Um Data Scientist   \n",
       "2             Seattle Data Guy   \n",
       "3                    Joma Tech   \n",
       "4             Seattle Data Guy   \n",
       "\n",
       "                                                    title  interesting  \\\n",
       "number                                                                   \n",
       "0                              How Data Engineering Works          1.0   \n",
       "1       [Parte 01] Como √© o Trabalho de um Data Engine...          0.0   \n",
       "2       Data Engineering Road Map - How To Learn Data ...          1.0   \n",
       "3       Data Scientists vs Data Engineers: Which one i...          1.0   \n",
       "4              What Skills Do Data Engineers Need To Know          1.0   \n",
       "\n",
       "       upload_date                      user  view_count  like_count  \\\n",
       "number                                                                 \n",
       "0       2021-03-17          AltexSoftChannel       70764        4014   \n",
       "1       2020-05-25  UCar5Cr-pVz08GY_6I3RX9bA       11125         814   \n",
       "2       2021-07-06  UCmLGJ3VYBcfRaWbP6JLJcpA       48598        2561   \n",
       "3       2019-12-19  UCV0qA-eDDICsRR9rPcnG7tw      246236        6683   \n",
       "4       2021-04-08  UCmLGJ3VYBcfRaWbP6JLJcpA       33370        1870   \n",
       "\n",
       "                                                thumbnail  width  height  \\\n",
       "number                                                                     \n",
       "0       https://i.ytimg.com/vi/qWru-b6m030/maxresdefau...   1920    1080   \n",
       "1       https://i.ytimg.com/vi_webp/nQu6s8FPhfA/maxres...   1920    1080   \n",
       "2       https://i.ytimg.com/vi_webp/SpaFPPByOhM/maxres...   1920    1080   \n",
       "3       https://i.ytimg.com/vi/vmYaAzbv9xk/maxresdefau...   1920    1080   \n",
       "4       https://i.ytimg.com/vi/LgSHaOvNodA/maxresdefau...   1920    1080   \n",
       "\n",
       "                  categories  \\\n",
       "number                         \n",
       "0       Science & Technology   \n",
       "1       Science & Technology   \n",
       "2                  Education   \n",
       "3                  Education   \n",
       "4                  Education   \n",
       "\n",
       "                                                     tags  \\\n",
       "number                                                      \n",
       "0       data engineering|data science|data infrastruct...   \n",
       "1       data engineer|engenheiro de dados o que faz|fo...   \n",
       "2       big data|data analytics|tableau|sql|big query|...   \n",
       "3       joma|vlog|data scientist|data science|data eng...   \n",
       "4       big data|data analytics|tableau|sql|big query|...   \n",
       "\n",
       "                                              channel_url  \\\n",
       "number                                                      \n",
       "0       https://www.youtube.com/channel/UCEKI_F16hUtBH...   \n",
       "1       https://www.youtube.com/channel/UCar5Cr-pVz08G...   \n",
       "2       https://www.youtube.com/channel/UCmLGJ3VYBcfRa...   \n",
       "3       https://www.youtube.com/channel/UCV0qA-eDDICsR...   \n",
       "4       https://www.youtube.com/channel/UCmLGJ3VYBcfRa...   \n",
       "\n",
       "                                              description  \n",
       "number                                                     \n",
       "0       So, the sole purpose of data engineering is to...  \n",
       "1       Nesse v√≠deo, eu vou mostrar qual o papel de um...  \n",
       "2       How do you go from 0 to data engineer?  What i...  \n",
       "3       üìö Video courses from JomaClass: üéì New to progr...  \n",
       "4       Learn More about data engineering Googles DE c...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Limpeza das datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:37:06.527480Z",
     "start_time": "2021-12-23T15:37:06.445340Z"
    }
   },
   "outputs": [],
   "source": [
    "df_limpo = pd.DataFrame(index=df.index)\n",
    "df_limpo['title'] = df['title']\n",
    "df_limpo['date'] = pd.to_datetime(df['upload_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Limpeza de views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:37:08.487841Z",
     "start_time": "2021-12-23T15:37:08.481008Z"
    }
   },
   "outputs": [],
   "source": [
    "views = df['view_count'].fillna(0)\n",
    "df_limpo['views'] = views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:02.171684Z",
     "start_time": "2021-12-23T15:38:01.659897Z"
    }
   },
   "outputs": [],
   "source": [
    "# As features vao ficar num dataset separado\n",
    "features = pd.DataFrame(index=df_limpo.index)\n",
    "\n",
    "# Y (target) tambem fica separado\n",
    "y = df['interesting'].copy()\n",
    "\n",
    "# Feature Enginneering\n",
    "today = datetime.datetime.today().strftime(\"%Y-%m-%d\")\n",
    "features['tempo_desde_pub'] = (pd.to_datetime(today) -  df_limpo['date']) / np.timedelta64(1, 'D')\n",
    "features['views'] = df_limpo['views']\n",
    "features['views_por_dia'] = (features['views'] / features['tempo_desde_pub']).round(3)\n",
    "features.drop(['tempo_desde_pub'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test\n",
    "\n",
    "Vamos dividir pela data, de forma que divida ao meioa s duas quantidade de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:03.432149Z",
     "start_time": "2021-12-23T15:38:03.367713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((546, 2), (1099, 2), (546,), (1099,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < '2020-03-10'\n",
    "mask_val = df_limpo['date'] >= '2020-03-10'\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:04.292529Z",
     "start_time": "2021-12-23T15:38:04.277892Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_por_dia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>246236</td>\n",
       "      <td>335.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         views  views_por_dia\n",
       "number                       \n",
       "3       246236        335.015"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:05.052808Z",
     "start_time": "2021-12-23T15:38:05.045975Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number\n",
       "3    1.0\n",
       "Name: interesting, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando com apenas uma feature (NLTK)\n",
    "\n",
    "Vamos usar um Vecotorizer para tokenizar os t√≠tulos e assim tentarmos fazer o treinamento s√≥ com palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:07.796042Z",
     "start_time": "2021-12-23T15:38:07.391656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Buscando somente o 'title' para fazer a tokeniza√ß√£o\n",
    "title_train = df_limpo[mask_train]['title']\n",
    "title_val = df_limpo[mask_val]['title']\n",
    "\n",
    "# Min df - minimo de vezes que palavra tem que aparecer pra virar coluna\n",
    "#        => min_df=2 quer dizer enta que a palavra tem que aparecer 2 vezes\n",
    "#           no minimo para ela representar uma nova coluna\n",
    "## ngram_range = vai fazer colunas para tanto 1 word \"machine\" quanto 2 juntas \"machine learning\"\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=2, ngram_range=(1,2))\n",
    "\n",
    "## Aplicando tokenizador\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convertemos o nosso titulo para um vetor de tamanho 1134, sendo esas a quantidade de palavras distintas**\n",
    "\n",
    "Como √© um array esparso (ou seja, esta preenhcido de muito zero) √© dif√≠cil por isso na tela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:09.051309Z",
     "start_time": "2021-12-23T15:38:09.045453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 802)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:09.968467Z",
     "start_time": "2021-12-23T15:38:09.959679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x802 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenando as vari√°vels num√©ricas com as geradas pelo TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:11.154816Z",
     "start_time": "2021-12-23T15:38:11.142123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((546, 804), (1099, 804))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle = sparse.hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = sparse.hstack([Xval, title_bow_val])\n",
    "Xtrain_wtitle.shape, Xval_wtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:15.836095Z",
     "start_time": "2021-12-23T15:38:12.278805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=4,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000,\n",
    "                             min_samples_leaf=1, \n",
    "                             random_state=0, \n",
    "                             class_weight='balanced', \n",
    "                             n_jobs=4)\n",
    "mdl.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:17.782126Z",
     "start_time": "2021-12-23T15:38:17.361305Z"
    }
   },
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle)[: ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:38:27.127089Z",
     "start_time": "2021-12-23T15:38:27.077296Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      " avg_precision :: 0.3197735929438541 \n",
      " roc_auc :: 0.6919486320491346\n"
     ]
    }
   ],
   "source": [
    "print('RandomForest')\n",
    "print( \" avg_precision :: \" + str(metrics.average_precision_score(yval, p)), '\\n' ,\n",
    "      \"roc_auc :: \" + str(metrics.roc_auc_score(yval, p)) )\n",
    "# RandomForest\n",
    "#  avg_precision :: 0.3876787322730141 \n",
    "#  roc_auc :: 0.6775564963329557"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor resultado que Mario encontrou para oe xemplo dele\n",
    "min_df=2 ngram_range=(1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T15:54:52.059388Z",
     "start_time": "2021-12-23T15:54:52.041811Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-db68a245795b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', n_jobs=4, random_state=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = LGBMClassifier(random_state=0, class_weight='balanced', n_jobs=4)\n",
    "mdl.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhavel/miniconda3/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - No Hyper-turning\n",
      " avg_precision :: 0.358824358569258 \n",
      " roc_auc :: 0.644678313755888\n"
     ]
    }
   ],
   "source": [
    "# metrics.average_precision_score(yval, p), metrics.roc_auc_score(yval, p)\n",
    "print('LightGBM - No Hyper-turning')\n",
    "print( \" avg_precision :: \" + str(metrics.average_precision_score(yval, p)), '\\n' ,\n",
    "      \"roc_auc :: \" + str(metrics.roc_auc_score(yval, p)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bayesian Optimization\n",
    "\n",
    "√â uma op√ß√¢o avan√ßada ao fazer GridSearch que √© demorado) e RandomSearch (√© melhor que o grid mas n√¢o tanto quanto Baysian).\n",
    "\n",
    "**Bayesian Optimization √â UM RANDOM-SEARCH OTIMIZADO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib: scikit optimizer\n",
    "from skopt import forest_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "def tune_lgbm(params):\n",
    "    # Set Hyper-params\n",
    "    tunning = {}\n",
    "    print()\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    # Sety TDF-Vec hyper-params, generate vocabulary and apply over data\n",
    "    title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    title_bow_train = title_vec.fit_transform(title_train)\n",
    "    title_bow_val = title_vec.transform(title_val)\n",
    "    # Join Numeric Features with TDF-Vec\n",
    "    Xtrain_wtitle = sparse.hstack([Xtrain, title_bow_train])\n",
    "    Xval_wtitle = sparse.hstack([Xval, title_bow_val])\n",
    "    # Create Model with hyper-params\n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                         min_child_samples=min_child_samples, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, bagging_freq=1, n_estimators=n_estimators,\n",
    "                        random_state=0, class_weight='balanced', n_jobs=4)\n",
    "    # Fit Model\n",
    "    mdl.fit(Xtrain_wtitle, ytrain)\n",
    "    # Predict\n",
    "    pred = mdl.predict_proba(Xval_wtitle)[:, 1]\n",
    "    print(metrics.roc_auc_score(yval, pred))\n",
    "    # Save Results\n",
    "    tunning['params'] = params\n",
    "    tunning['roc'] = metrics.roc_auc_score(yval, pred)\n",
    "    tunning['avg_prec'] = metrics.average_precision_score(yval, pred)\n",
    "    results.append(tunning)\n",
    "    \n",
    "    # Esta negativa pois eu quero maximizar a average-precision\n",
    "    # como nao tem um 'skopt.forest_maximze' entao eu inverto a avg_precision para ter esse efeito de maximizar\n",
    "    return -metrics.average_precision_score(yval, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERVALOS DOS HYPER-PARAMETROS  DO LIGHT-GBM E TDF-VEC\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # learning-rate : usamos log-unifrom para ter mais chance de pegar valores pequenos\n",
    "         (1,10), # max_depth\n",
    "         (1,20), # min_child_samples\n",
    "         (0.05, 1.), # subsample\n",
    "         (0.05, 1.), # colsample_bytree\n",
    "         (100, 1000), # n_estimators\n",
    "         (1,5), # TDF-Vectorizer: min_df\n",
    "         (1,5)] # TDF-Vectorizer: ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EXEC skopt.forest_minimize (Baysian Optimization)\n",
    "res = forest_minimize(tune_lgbm, # fun√ß√¢o apra testar score que voce quer MINIMIZAR\n",
    "                      space,  # hyper-paremtros e seu range\n",
    "                      random_state=160745,\n",
    "                      n_random_starts=20, # testar 20 vezes\n",
    "                      n_calls=50, \n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ END OF PROCESS ==============\n",
    "# Iteration No: 50 ended. Search finished for the next optimal point.\n",
    "# Time taken: 22.8565\n",
    "# Function value obtained: -0.3677\n",
    "# Current minimum: -0.4024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003924937303997735,\n",
       " 10,\n",
       " 9,\n",
       " 0.42896739513988846,\n",
       " 0.08080324515701484,\n",
       " 196,\n",
       " 1,\n",
       " 5]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhores parametros encontrados pelo Baysian Optimizer\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [0.003924937303997735,\n",
       "  10,\n",
       "  9,\n",
       "  0.42896739513988846,\n",
       "  0.08080324515701484,\n",
       "  196,\n",
       "  1,\n",
       "  5],\n",
       " 'roc': 0.6723749329199212,\n",
       " 'avg_prec': 0.40242103560963294}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AL√©m de mostra os parametros, mostra a precision e roc auc dos melhores paremetros\n",
    "sorted(results, key = lambda i: i['avg_prec'],reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Reg\n",
    "\n",
    "Vamos testar: Usando spo StandarScale e s√≥ MaxABsScaler. Par afazer isso, temos que comentar e descomentar os trehcos de c√≥digo a seguir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhavel/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/home/rhavel/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/home/rhavel/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/home/rhavel/miniconda3/lib/python3.9/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_wtitle2 = sparse.csr_matrix(Xtrain_wtitle.copy())\n",
    "Xval_wtitle2 = sparse.csr_matrix(Xval_wtitle.copy())\n",
    "\n",
    "scaler = StandardScaler() ## Para variaveis numericas\n",
    "# scaler = MaxAbsScaler() ## Para variaveis sparsas (o array gigante de vocabulario)\n",
    "\n",
    "Xtrain_wtitle2[: , :2] = scaler.fit_transform(Xtrain_wtitle2[:, :2].todense())\n",
    "Xval_wtitle2[:, :2] = scaler.transform(Xval_wtitle2[:, :2].todense())\n",
    "\n",
    "# Xtrain_wtitle2 = scaler.fit_transform(Xtrain_wtitle2)\n",
    "# Xval_wtitle2 = scaler.transform(Xval_wtitle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 1136)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_wtitle2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, n_jobs=4, random_state=4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = LogisticRegression(C=0.5, n_jobs=4, random_state=4)\n",
    "mdl.fit(Xtrain_wtitle2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41578009994342235, 0.6897143879315486)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.average_precision_score(yval, p), metrics.roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rafael\n",
    "## (0.4147342546287094, 0.6589231411364855) - C=0.5 MaxAbScaler\n",
    "## (0.41578009994342235, 0.6897143879315486) -  C=0.5 StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mario Filho\n",
    "# (0.4043414314912761, 0.6789338739490788) - sem tunning StandardScaler\n",
    "# (0.3988238048468208, 0.6462226462345716) - sem tunning MaxAbScaler\n",
    "# (0.33826219541849384, 0.6082881163913899) - C=10, MaxAbScaler\n",
    "# (0.41472090277819385, 0.6588873650945083) - C=0.5 MaxAbScaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
