{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ee7905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:25:59.061350Z",
     "start_time": "2021-12-25T15:25:59.055360Z"
    }
   },
   "outputs": [],
   "source": [
    "DB_HOST    = 'ec2-54-237-124-68.compute-1.amazonaws.com'\n",
    "DB_USER    = 'tutwpjujzkfpym'\n",
    "DB_PORT    = '5432'\n",
    "DB_PASS    = '5e3ec8bc2661a3285c6324297a2dc2d589074407119c4550ebb1b69355c08dec'\n",
    "DB_NAME    = 'dt34hsa1qkeo6'\n",
    "DB_TABLE   = 'data_engine_recomender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec18a02b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:25:59.504836Z",
     "start_time": "2021-12-25T15:25:59.207349Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import psycopg2\n",
    "\n",
    "class DataBase:\n",
    "\n",
    "    TABLE_NAME = DB_TABLE\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conn = self.connect_postgres()\n",
    "        self.cur = self.conn.cursor()\n",
    "\n",
    "    def connect_postgres(self):\n",
    "        # connect to PostgreSQL\n",
    "        print (\"\\nconnecting to PostgreSQL\")\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=DB_NAME, user=DB_USER, password=DB_PASS,\n",
    "                host=DB_HOST, port=DB_PORT\n",
    "            )\n",
    "        except Exception as err:\n",
    "            print (\"PostgreSQL Connect() ERROR:\", err)\n",
    "            conn = None\n",
    "        # return the connection object\n",
    "        return conn\n",
    "\n",
    "    def create_table():\n",
    "        self.cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "                id SERIAL primary key, \n",
    "                video_title TEXT, \n",
    "                video_link TEXT UNIQUE, \n",
    "                thumbnail TEXT, \n",
    "                score FLOAT, \n",
    "                liked BOOLEAN DEFAULT FALSE,\n",
    "                created_at TIMESTAMP DEFAULT NOW(),\n",
    "                updated_at DATE);\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "        self.close()   \n",
    "\n",
    "    def show_videos(self, qtd_videos = 20):\n",
    "        \"\"\" Return list of videos for Front End \"\"\"\n",
    "        query = '''select id, video_title, video_link, thumbnail, score, liked from {TABLE_NAME}\n",
    "                    order by score desc limit {qtd_videos}'''\n",
    "        videos = self.cur.execute(query)\n",
    "        result = videos.fetchall()\n",
    "        self.close() \n",
    "        return result\n",
    "\n",
    "    def get_by_link(self, video_link):\n",
    "        \"\"\" Return one video by its link \"\"\"\n",
    "        query = '''SELECT id from {TABLE_NAME} where video_link = \"{video_link}\" '''\n",
    "        video = self.cur.execute(query)\n",
    "        self.close() \n",
    "        return video.fetchone()\n",
    "\n",
    "    def save_recomendation(self, video_info):\n",
    "        ''' check if video already exists '''\n",
    "        video_exists = self.get_by_link(video_info['video_id'])\n",
    "\n",
    "        if video_exists:\n",
    "            return True\n",
    "\n",
    "        video_title = video_info['title'].replace('\"', \"'\"),\n",
    "        video_link = video_info['video_id'],\n",
    "        thumbnail = video_info['thumbnail'],\n",
    "        score = video_info['score']\n",
    "\n",
    "        query = '''INSERT INTO {TABLE_NAME} (video_title, video_link, thumbnail, score) values \n",
    "                                (\"{video_title}\", \"{video_link}\", \"{thumbnail}\", {score});\n",
    "                '''\n",
    "        new_video = self.cur.execute(query)\n",
    "        self.close()\n",
    "    \n",
    "    def like_video(self, liked_value, video_id):\n",
    "        \"\"\"\" Edit liked column \"\"\"\n",
    "        update_time = datetime.datetime.now().strftime(\"%Y %m %d %H:%M:%S\")\n",
    "\n",
    "\n",
    "        query = '''update {TABLE_NAME} set liked = {liked_value},\n",
    "                        updated_at = '{update_time}' where id = {video_id}\n",
    "                '''\n",
    "        self.cur.execute(query)\n",
    "        self.close()\n",
    "\n",
    "    def close(self):\n",
    "        self.cur.close()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffc4bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.162322Z",
     "start_time": "2021-12-25T15:25:59.507839Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3864/2147869371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import joblib as jb\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# mdl_rf = pickle.load( open( \"random_forest_20200911\", \"rb\" ) )\n",
    "# mdl_lgbm = pickle.load( open( \"lgbm_20200911\", \"rb\" ) )\n",
    "# title_vec = pickle.load( open( \"title_vectorizer_20200911\", \"rb\" ) )\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "#  '/' for POSIX and '\\\\' for Windows\n",
    "\n",
    "ml_logistic = jb.load(\"logistic_reg_2021-12-23.pkl.z\")\n",
    "title_vec = jb.load(\"title_vectorizer_2021-12-23.pkl.z\")\n",
    "\n",
    "def clean_date(data):\n",
    "    return pd.to_datetime(data['upload_date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "def clean_views(data):\n",
    "    raw_views_str = data['view_count']\n",
    "    if raw_views_str is None:\n",
    "        return 0\n",
    "    return int(raw_views_str)\n",
    "\n",
    "def compute_features(data):\n",
    "\n",
    "    publish_date = clean_date(data)\n",
    "    if publish_date is None:\n",
    "        return None\n",
    "\n",
    "    views = clean_views(data)\n",
    "    title = data['title']\n",
    "\n",
    "    features = dict()\n",
    "\n",
    "    features['tempo_desde_pub'] = (pd.Timestamp.today() - publish_date) / np.timedelta64(1, 'D')\n",
    "    features['views'] = views\n",
    "    features['views_por_dia'] = features['views'] / features['tempo_desde_pub']\n",
    "    del features['tempo_desde_pub']\n",
    "\n",
    "    vectorized_title = title_vec.transform([title])\n",
    "\n",
    "    num_features = sparse.csr_matrix(np.array([features['views'], features['views_por_dia']]))\n",
    "    feature_array = sparse.hstack([num_features, vectorized_title])\n",
    "\n",
    "    return feature_array\n",
    "\n",
    "\n",
    "def compute_prediction(data):\n",
    "    feature_array = compute_features(data)\n",
    "\n",
    "    if feature_array is None:\n",
    "        return 0\n",
    "\n",
    "    # p_rf = mdl_rf.predict_proba(feature_array)[0][1]\n",
    "    # p_lgbm = mdl_lgbm.predict_proba(feature_array)[0][1]\n",
    "    # p = 0.2*p_rf + 0.8*p_lgbm\n",
    "\n",
    "    prob = ml_logistic.predict_proba(feature_array)[0][1]\n",
    "    log_data(data, feature_array, proba)\n",
    "\n",
    "    return p\n",
    "\n",
    "def log_data(data, feature_array, p):\n",
    "    #print(data)\n",
    "    video_id = data.get('og:video:url', '')\n",
    "    data['prediction'] = p\n",
    "    data['feature_array'] = feature_array.todense().tolist()\n",
    "    #print(video_id, json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fb18a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.166315Z",
     "start_time": "2021-12-25T15:26:08.166315Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from threading import Thread\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "queries = ['data+engineering', 'data+pipeline', \"airflow\"]\n",
    "\n",
    "\n",
    "# Em suma: busca novos dados, aplica o modelo\n",
    "def update_db():\n",
    "    try:\n",
    "        database = DataBase()\n",
    "        for query in queries:\n",
    "            \n",
    "            for page in range(1,4):\n",
    "                print(query, page)\n",
    "                search_page = download_search_page(query, page)\n",
    "                print(\"=========================\")\n",
    "                print(\" *** search_page ***\")\n",
    "                print(search_page)\n",
    "                print(\"=========================\")\n",
    "                video_list = parse_search_page(search_page)\n",
    "                print(\"=========================\")\n",
    "                print(\" *** video_list ***\")\n",
    "                print(video_list)\n",
    "                print(\"=========================\")\n",
    "                df_videos = pd.DataFrame(video_list)\n",
    "                \n",
    "                for video in df_videos['link'].unique():\n",
    "                    if database.get_by_link(video):\n",
    "                        print(\"Already registered in database: {}\".format(video))\n",
    "                        continue\n",
    "                    video_json_data = parse_video_page(video)\n",
    "                    if(not video_json_data):\n",
    "                        continue\n",
    "                    \n",
    "                    p = compute_prediction(video_json_data)\n",
    "\n",
    "                    video_id = video\n",
    "                    data_front = {\n",
    "                        \"title\": video_json_data['title'],\n",
    "                        \"score\": float(p),\n",
    "                        \"video_id\": video_id,\n",
    "                        \"thumbnail\": video_json_data['thumbnail']\n",
    "                       }\n",
    "                    data_front['update_time'] = time.time_ns()\n",
    "                    print(video_id, json.dumps(data_front))\n",
    "                    database.save_recomendation(data_front)\n",
    "    except Exception as identifier:\n",
    "        # os.remove(\"novos_videos.json\")\n",
    "        print(\"================\", identifier)\n",
    "        raise Exception('Internal Server Error')\n",
    "    return True\n",
    "\n",
    "    \"\"\"\n",
    "O que vai fazer:\n",
    " + Para cada query: \n",
    "  - Web Scraping\n",
    "  - Buaca os dadoa de de uma pagina por query e por fim  os video\n",
    "    - Buca novos videos desde que nao ja esstjam instalados \n",
    "      - é testtado com um select\n",
    "      - si é permidido, o video é convertido\n",
    "    - Com os dados no formato JSON faz a previsao\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a60248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.168315Z",
     "start_time": "2021-12-25T15:26:08.168315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Paste\n",
    "import requests as rq\n",
    "import bs4 as bs4\n",
    "import re\n",
    "import time\n",
    "import youtube_dl \n",
    "import asyncio\n",
    "from requests_html import HTMLSession, AsyncHTMLSession\n",
    "\n",
    "def download_search_page(query, page):\n",
    "    url = \"https://www.youtube.com/results?search_query={query}&sp=CAI%253D&p={page}\"\n",
    "    urll = url.format(query=query, page=page)\n",
    "    session = HTMLSession()\n",
    "    # enviado requisição para o youtube\n",
    "    response = session.get(urll)\n",
    "    print(\"=========================\")\n",
    "    print(\" *** response ***\")\n",
    "    print(response)\n",
    "    print(\"=========================\")\n",
    "    # executando Java-script\n",
    "    # t = Thread(target=render_html)\n",
    "    # ORIGINAL :: response.html.render(sleep=1)\n",
    "    return response.html.html\n",
    "\n",
    "\n",
    "def download_video_page(link):\n",
    "    url = \"https://www.youtube.com{link}\"\n",
    "    urll = url.format(link=link)\n",
    "    response = rq.get(urll)\n",
    "    link_name = re.search(\"v=(.*)\", link).group(1)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def parse_search_page(page_html):\n",
    "     # Processando a página html\n",
    "    parsed = bs4.BeautifulSoup(page_html, \"html.parser\")\n",
    "    video_list = []\n",
    "     # Buscando todas as tags \"a\" com o id \"video-title\"\n",
    "    ancors = parsed.find_all('a', attrs={\"id\": \"video-title\"})\n",
    "    for e in ancors:\n",
    "        link = e['href']\n",
    "        title = e['title']\n",
    "        data = {\"link\": link, \"title\": title}\n",
    "        video_list.append(data)\n",
    "    return video_list\n",
    "\n",
    "def parse_video_page(video_link):\n",
    "    URL = \"https://www.youtube.com{link}\"\n",
    "    ydl = youtube_dl.YoutubeDL({\"ignoreerrors\": True, 'verbose':False})\n",
    "    try:\n",
    "        r = ydl.extract_info(url=URL.format(link=video_link), download=False)\n",
    "        year = r['upload_date'][:4]\n",
    "        month = r['upload_date'][4:6]\n",
    "        day = r['upload_date'][6:]\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    video_info = {\n",
    "        'uploader': r['uploader'],\n",
    "        'title': r['title'],\n",
    "        'upload_date': f\"{year}-{month}-{day}\",\n",
    "        'user': r['uploader_id'],\n",
    "        'view_count': r['view_count'],\n",
    "        'like_count': r['like_count'],\n",
    "        'dislike_count': 0,\n",
    "        'thumbnail': r['thumbnail'],\n",
    "        'width': r['width'],\n",
    "        'height': r['height'],\n",
    "        'categories': '|'.join(r['categories']) if r['categories'] is not None else None,\n",
    "        'tags': '|'.join(r['tags']) if r['tags'] is not None else None,\n",
    "        'channel_url': r['channel_url'],\n",
    "        'description': r['description']\n",
    "    }\n",
    "\n",
    "    return video_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944cade",
   "metadata": {},
   "source": [
    "## Atualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add80301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:35.613357Z",
     "start_time": "2021-12-25T15:26:35.598368Z"
    }
   },
   "outputs": [],
   "source": [
    "# data+engineering, 1 a 4\n",
    "def download_search_page(query, page):\n",
    "    url = \"https://www.youtube.com/results?search_query={query}&sp=CAI%253D&p={page}\"\n",
    "    urll = url.format(query=query, page=page)\n",
    "    session = HTMLSession()\n",
    "    # enviado requisição para o youtube\n",
    "    response = session.get(urll)\n",
    "    print(\"=========================\")\n",
    "    print(\" *** response ***\")\n",
    "    print(response)\n",
    "    print(\"=========================\")\n",
    "    # executando Java-script\n",
    "    # t = Thread(target=render_html)\n",
    "    # ORIGINAL :: response.html.render(sleep=1)\n",
    "    return response.html.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c3468f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:42.186213Z",
     "start_time": "2021-12-25T15:26:36.253982Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\youtube_dl\\extractor\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlazy_extractors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlazy_extractors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_ALL_CLASSES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'youtube_dl.extractor.lazy_extractors'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3864/4083621602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# OLd de 01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0myoutube_dl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'data+engineering'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data+pipeline'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"airflow\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.youtube.com/results?search_query={query}&sp=EgIIAg%253D%253D&p={page}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\youtube_dl\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mFileDownloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m )\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextractor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_extractors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_extractors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madobepass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSO_INFO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mYoutubeDL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYoutubeDL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\youtube_dl\\extractor\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0m_LAZY_LOADER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextractors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     _ALL_CLASSES = [\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\youtube_dl\\extractor\\extractors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    723\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmyvidster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMyVidsterIE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m from .nationalgeographic import (\n\u001b[0m\u001b[0;32m    725\u001b[0m     \u001b[0mNationalGeographicVideoIE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[0mNationalGeographicTVIE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OLd de 01\n",
    "import youtube_dl\n",
    "\n",
    "queries = ['data+engineering', 'data+pipeline', \"airflow\"]\n",
    "url = \"https://www.youtube.com/results?search_query={query}&sp=EgIIAg%253D%253D&p={page}\"\n",
    "\n",
    "ydl = youtube_dl.YoutubeDL({\"ignoreerrors\": True, 'verbose':False, \"date\": \"2021-12-12\"})\n",
    "\n",
    "# Demora cerca de 50min (indepndende da maquina)\n",
    "resultados = []\n",
    "for query in queries:\n",
    "    # yt-search-1100 : Busque por até 1100 Videos para consulta (busca no max 35pag = 500videos) \n",
    "    # 570 para data-enginering, 646 para data-pipeline\n",
    "    r = ydl.extract_info(\"ytsearch1000:{}\".format(query), download=False, extra_info={\"date\": \"2021-12-12\"})\n",
    "    for entry in r['entries']:\n",
    "        # adicionar a query usada para pegar aquele video\n",
    "        if entry is not None:\n",
    "            entry['query'] = query\n",
    "    resultados += r['entries']\n",
    "    \n",
    "# Filtragem, pois pode aparecer algum 'None' entao, ele deve ser retirada da lsita de videos\n",
    "resultados = [e for e in resultados if e is not None]\n",
    "len(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b25652",
   "metadata": {},
   "source": [
    "### Get Search Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18798872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:47.878896Z",
     "start_time": "2021-12-25T15:26:45.326197Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import youtube_dl\n",
    "\n",
    "def download_search_page(keyword, n_of_videos):\n",
    "    video_links = []\n",
    "    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    ydl = youtube_dl.YoutubeDL({\"ignoreerrors\": True, 'verbose':False, \"date\": today})\n",
    "    # Faz a busca usando \n",
    "    result_search = ydl.extract_info(\"ytsearch{}:{}\".format(n_of_videos, keyword),\n",
    "                     download=False, extra_info={\"date\": today})\n",
    "    # Altera cada elemnto do resultado\n",
    "    for video_link in result_search['entries']:\n",
    "         if video_link is not None:\n",
    "            video_link['query'] = keyword\n",
    "    video_links += result_search['entries']\n",
    "    return video_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac4dcee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:54.788128Z",
     "start_time": "2021-12-25T15:26:48.788969Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Downloading playlist: data+engineering\n",
      "[youtube:search] query \"data+engineering\": Downloading page 1\n",
      "[youtube:search] playlist data+engineering: Downloading 5 videos\n",
      "[download] Downloading video 1 of 5\n",
      "[youtube] qWru-b6m030: Downloading webpage\n",
      "[download] Downloading video 2 of 5\n",
      "[youtube] SpaFPPByOhM: Downloading webpage\n",
      "[download] Downloading video 3 of 5\n",
      "[youtube] nQu6s8FPhfA: Downloading webpage\n",
      "[youtube] nQu6s8FPhfA: Downloading MPD manifest\n",
      "[download] Downloading video 4 of 5\n",
      "[youtube] vmYaAzbv9xk: Downloading webpage\n",
      "[download] Downloading video 5 of 5\n",
      "[youtube] AS2EyYK4x_Q: Downloading webpage\n",
      "[download] Finished downloading playlist: data+engineering\n"
     ]
    }
   ],
   "source": [
    "r_donwload_search = download_search_page('data+engineering', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce781bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:58.066042Z",
     "start_time": "2021-12-25T15:26:58.053050Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_only_url(obj):\n",
    "    return obj['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a369b8dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:58.539596Z",
     "start_time": "2021-12-25T15:26:58.512612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qWru-b6m030', 'SpaFPPByOhM', 'nQu6s8FPhfA', 'vmYaAzbv9xk', 'AS2EyYK4x_Q']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_filter = list(map(get_only_url, r_donwload_search))\n",
    "r_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414e23c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.185304Z",
     "start_time": "2021-12-25T15:26:08.185304Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_only_url(list_videos):\n",
    "    return list(map(lambda el: el['id'], r_donwload_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e94078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.191300Z",
     "start_time": "2021-12-25T15:26:08.191300Z"
    }
   },
   "outputs": [],
   "source": [
    "get_only_url(r_donwload_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4074fe",
   "metadata": {},
   "source": [
    "### Get Video Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e55941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.193298Z",
     "start_time": "2021-12-25T15:26:08.193298Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_video_page(video_link):\n",
    "    URL = \"https://www.youtube.com/watch?v={link}\"\n",
    "    ydl = youtube_dl.YoutubeDL({\"ignoreerrors\": True, 'verbose':False})\n",
    "    try:\n",
    "        r = ydl.extract_info(url=URL.format(link=video_link), download=False)\n",
    "        year = r['upload_date'][:4]\n",
    "        month = r['upload_date'][4:6]\n",
    "        day = r['upload_date'][6:]\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    video_info = {\n",
    "        'link': video_link,\n",
    "        'uploader': r['uploader'],\n",
    "        'title': r['title'],\n",
    "        'upload_date': f\"{year}-{month}-{day}\",\n",
    "        'user': r['uploader_id'],\n",
    "        'view_count': r['view_count'],\n",
    "        'like_count': r['like_count'],\n",
    "        'dislike_count': 0,\n",
    "        'thumbnail': r['thumbnail'],\n",
    "        'width': r['width'],\n",
    "        'height': r['height'],\n",
    "        'categories': '|'.join(r['categories']) if r['categories'] is not None else None,\n",
    "        'tags': '|'.join(r['tags']) if r['tags'] is not None else None,\n",
    "        'channel_url': r['channel_url'],\n",
    "        'description': r['description']\n",
    "    }\n",
    "\n",
    "    return video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8af465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.196298Z",
     "start_time": "2021-12-25T15:26:08.196298Z"
    }
   },
   "outputs": [],
   "source": [
    "for el in r_filter:\n",
    "    print(download_video_page(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af225d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.199295Z",
     "start_time": "2021-12-25T15:26:08.199295Z"
    }
   },
   "outputs": [],
   "source": [
    "video_list = list(map(download_video_page, get_only_url(r_donwload_search)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534172ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.203292Z",
     "start_time": "2021-12-25T15:26:08.203292Z"
    }
   },
   "outputs": [],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5da968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.206291Z",
     "start_time": "2021-12-25T15:26:08.206291Z"
    }
   },
   "outputs": [],
   "source": [
    "df_videos = pd.DataFrame(video_list)\n",
    "df_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136dd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T15:26:08.208289Z",
     "start_time": "2021-12-25T15:26:08.208289Z"
    }
   },
   "outputs": [],
   "source": [
    "df_videos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56613e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84768e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bb9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a1c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
