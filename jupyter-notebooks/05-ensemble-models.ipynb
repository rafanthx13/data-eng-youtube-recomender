{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "\n",
    "````\n",
    "# RDF\n",
    "#  (0.39545173300116343, 0.6776220857432473)\n",
    "# LightGBM HTuned\n",
    "# (0.39010753360298556, 0.6728221334446366)\n",
    "# Logistic\n",
    "# (0.4295233599530305, 0.671194323534673)\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import bs4 as bs4\n",
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "pd.set_option(\"max.columns\", 131)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "import joblib as jb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#https://strftime.org/\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_data_all_labeled2.csv\", index_col=0).dropna(subset=[\"y\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uploader</th>\n",
       "      <th>title</th>\n",
       "      <th>y</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>user</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>channel_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yanjun Qi</td>\n",
       "      <td>S0-Introduction-Module3: Deep Learning and AI ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>UCHMYETgeGbNHVHLidZSV8BQ</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://i.ytimg.com/vi/LkPmTGw1jqo/hqdefault.j...</td>\n",
       "      <td>1280</td>\n",
       "      <td>672</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>http://www.youtube.com/channel/UCHMYETgeGbNHVH...</td>\n",
       "      <td>Course Web: \\nhttps://qiyanjun.github.io/2020f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ciência dos Dados</td>\n",
       "      <td>Machine Learning no Ensino Médio</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>UCd3ThZLzVDDnKSZMsbK0icg</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://i.ytimg.com/vi_webp/R_gBq8IfwJc/maxres...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Education</td>\n",
       "      <td>machine learning|data science</td>\n",
       "      <td>http://www.youtube.com/channel/UCd3ThZLzVDDnKS...</td>\n",
       "      <td>A matemática, sempre ela....\\n\\nDe uma maneira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iKennyHD</td>\n",
       "      <td>NBA LIVE 22: EA COULD USE DEEP MACHINE LEARNIN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>KennyCallOfDuty</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://i.ytimg.com/vi/Tix2xon9MSs/maxresdefau...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>iKennyHD|nba live20|nba live 20|nba 2k20|live2...</td>\n",
       "      <td>http://www.youtube.com/channel/UCGMtoj9V9Go_im...</td>\n",
       "      <td>Wanna Donate? paypal.me/iKennyYT is where you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>Amazon Aurora Machine Learning – SageMaker Int...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>AmazonWebServices</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://i.ytimg.com/vi/w-2ip78NxAw/maxresdefau...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>AWS|Amazon Web Services|Cloud|AWS Cloud|Cloud ...</td>\n",
       "      <td>http://www.youtube.com/channel/UCd6MoB9NC6uYN2...</td>\n",
       "      <td>Learn how you can turn relational data into in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMRIT, Rajam, AP</td>\n",
       "      <td>Machine Learning and Deep Learning Implementat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>UC8g7hz4oXFzXNryt8h1gRPw</td>\n",
       "      <td>1486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://i.ytimg.com/vi/f6XIY_M7FlA/hqdefault.j...</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.youtube.com/channel/UC8g7hz4oXFzXNr...</td>\n",
       "      <td>Resource Person\\nMr.S.Aravinth Seshadri\\nCerti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              uploader                                              title  \\\n",
       "0            Yanjun Qi  S0-Introduction-Module3: Deep Learning and AI ...   \n",
       "1    Ciência dos Dados                   Machine Learning no Ensino Médio   \n",
       "2             iKennyHD  NBA LIVE 22: EA COULD USE DEEP MACHINE LEARNIN...   \n",
       "3  Amazon Web Services  Amazon Aurora Machine Learning – SageMaker Int...   \n",
       "4     GMRIT, Rajam, AP  Machine Learning and Deep Learning Implementat...   \n",
       "\n",
       "     y upload_date                      user  view_count  like_count  \\\n",
       "0  0.0  2020-08-25  UCHMYETgeGbNHVHLidZSV8BQ          22         NaN   \n",
       "1  0.0  2020-08-25  UCd3ThZLzVDDnKSZMsbK0icg           3         NaN   \n",
       "2  0.0  2020-08-25           KennyCallOfDuty          47         NaN   \n",
       "3  0.0  2020-08-25         AmazonWebServices         335         NaN   \n",
       "4  1.0  2020-08-25  UC8g7hz4oXFzXNryt8h1gRPw        1486         NaN   \n",
       "\n",
       "   dislike_count                                          thumbnail  width  \\\n",
       "0            NaN  https://i.ytimg.com/vi/LkPmTGw1jqo/hqdefault.j...   1280   \n",
       "1            NaN  https://i.ytimg.com/vi_webp/R_gBq8IfwJc/maxres...   1920   \n",
       "2            NaN  https://i.ytimg.com/vi/Tix2xon9MSs/maxresdefau...   1920   \n",
       "3            NaN  https://i.ytimg.com/vi/w-2ip78NxAw/maxresdefau...   1920   \n",
       "4            NaN  https://i.ytimg.com/vi/f6XIY_M7FlA/hqdefault.j...   1280   \n",
       "\n",
       "   height            categories  \\\n",
       "0     672  Science & Technology   \n",
       "1    1080             Education   \n",
       "2    1080                Gaming   \n",
       "3    1080  Science & Technology   \n",
       "4     720        People & Blogs   \n",
       "\n",
       "                                                tags  \\\n",
       "0                                   Machine Learning   \n",
       "1                      machine learning|data science   \n",
       "2  iKennyHD|nba live20|nba live 20|nba 2k20|live2...   \n",
       "3  AWS|Amazon Web Services|Cloud|AWS Cloud|Cloud ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         channel_url  \\\n",
       "0  http://www.youtube.com/channel/UCHMYETgeGbNHVH...   \n",
       "1  http://www.youtube.com/channel/UCd3ThZLzVDDnKS...   \n",
       "2  http://www.youtube.com/channel/UCGMtoj9V9Go_im...   \n",
       "3  http://www.youtube.com/channel/UCd6MoB9NC6uYN2...   \n",
       "4  http://www.youtube.com/channel/UC8g7hz4oXFzXNr...   \n",
       "\n",
       "                                         description  \n",
       "0  Course Web: \\nhttps://qiyanjun.github.io/2020f...  \n",
       "1  A matemática, sempre ela....\\n\\nDe uma maneira...  \n",
       "2  Wanna Donate? paypal.me/iKennyYT is where you ...  \n",
       "3  Learn how you can turn relational data into in...  \n",
       "4  Resource Person\\nMr.S.Aravinth Seshadri\\nCerti...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = pd.DataFrame(index=df.index)\n",
    "df_limpo['title'] = df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limpeza da data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo['date'] = pd.to_datetime(df['upload_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpeza de Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = df['view_count'].fillna(0)\n",
    "df_limpo['views'] = views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df_limpo.index)\n",
    "y = df['y'].copy()\n",
    "today = datetime.datetime.today().strftime(\"%Y-%m-%d\")\n",
    "features['tempo_desde_pub'] = (pd.to_datetime(today) -  df_limpo['date']) / np.timedelta64(1, 'D')\n",
    "features['views'] = df_limpo['views']\n",
    "features['views_por_dia'] = (features['views'] / features['tempo_desde_pub']).round(3)\n",
    "features.drop(['tempo_desde_pub'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaders = df['uploader'].str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = pd.concat([df_limpo, uploaders], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>1littlecoder</th>\n",
       "      <th>365 Data Science</th>\n",
       "      <th>:CodeWebsDuh :</th>\n",
       "      <th>A.I.M Learning</th>\n",
       "      <th>AI Coding</th>\n",
       "      <th>AI Learner hub</th>\n",
       "      <th>AI era</th>\n",
       "      <th>AICamp</th>\n",
       "      <th>AIPRA</th>\n",
       "      <th>AP2V Academy</th>\n",
       "      <th>ASQStatsDivision</th>\n",
       "      <th>AWS Online Tech Talks</th>\n",
       "      <th>Aakash N S</th>\n",
       "      <th>Abacus AI</th>\n",
       "      <th>Abhishek Agarrwal</th>\n",
       "      <th>Abhishek Thakur</th>\n",
       "      <th>Abuzar Ghaffari</th>\n",
       "      <th>Academind</th>\n",
       "      <th>Accenture</th>\n",
       "      <th>Accenture in the Philippines</th>\n",
       "      <th>Acsia Technologies</th>\n",
       "      <th>Adriano Gianini</th>\n",
       "      <th>Adriano Marcos Rodrigues Figueiredo</th>\n",
       "      <th>Adventures in the Cloud</th>\n",
       "      <th>Affiliate World Conferences</th>\n",
       "      <th>Ahmed Nour</th>\n",
       "      <th>Akash Dash</th>\n",
       "      <th>Albert Coronado</th>\n",
       "      <th>Alberto Olla</th>\n",
       "      <th>Alex The Analyst</th>\n",
       "      <th>Alexander Amini</th>\n",
       "      <th>Algoritma Data Science School</th>\n",
       "      <th>Ali Nemati</th>\n",
       "      <th>All About GATE Exam</th>\n",
       "      <th>Alteryx</th>\n",
       "      <th>AltexSoft</th>\n",
       "      <th>Alura Cursos Online</th>\n",
       "      <th>AmandaLovesToAudit</th>\n",
       "      <th>Amanpour and Company</th>\n",
       "      <th>Amarpreet Singh</th>\n",
       "      <th>Amaze Lab</th>\n",
       "      <th>Amazon Web Services</th>\n",
       "      <th>Amod Sachintha</th>\n",
       "      <th>Analytics India Magazine</th>\n",
       "      <th>Analytics Vidhya</th>\n",
       "      <th>Andrew Schonfeld</th>\n",
       "      <th>Andrey Sozykin</th>\n",
       "      <th>André Furchner</th>\n",
       "      <th>Andy Jake</th>\n",
       "      <th>Aniedi Udo-Obong</th>\n",
       "      <th>Applied AI Course</th>\n",
       "      <th>Art of Engineer</th>\n",
       "      <th>Artificial Intelligence Tutorials</th>\n",
       "      <th>Arvind Kumawat</th>\n",
       "      <th>Ashutoshh Singh</th>\n",
       "      <th>Ashvin Nair</th>\n",
       "      <th>Association Quantum</th>\n",
       "      <th>Association for Computing Machinery (ACM)</th>\n",
       "      <th>Asumsi</th>\n",
       "      <th>AtomsTalk</th>\n",
       "      <th>Australian Institute for Machine Learning</th>\n",
       "      <th>BEPEC - Career Transition Simplified</th>\n",
       "      <th>...</th>\n",
       "      <th>Whirldata</th>\n",
       "      <th>WhiteHatHacking</th>\n",
       "      <th>Wikitechy</th>\n",
       "      <th>XCTEQ Limited</th>\n",
       "      <th>Xuming Wang</th>\n",
       "      <th>YANGCOM Korea</th>\n",
       "      <th>Yanjun Qi</th>\n",
       "      <th>Yannic Kilcher</th>\n",
       "      <th>Yudi J</th>\n",
       "      <th>Yury Kashnitsky</th>\n",
       "      <th>Zach Star</th>\n",
       "      <th>ZaranTech</th>\n",
       "      <th>Zeeshan Usmani</th>\n",
       "      <th>a ydobon</th>\n",
       "      <th>akshay shekkari</th>\n",
       "      <th>ankitrathi.com</th>\n",
       "      <th>anıl Kaynar</th>\n",
       "      <th>ashish pondit</th>\n",
       "      <th>bespokeDS</th>\n",
       "      <th>biostatistique</th>\n",
       "      <th>codebasics</th>\n",
       "      <th>danny iskandar</th>\n",
       "      <th>datasciencearth</th>\n",
       "      <th>deeplizard</th>\n",
       "      <th>e-tube KTU by jasmin</th>\n",
       "      <th>eMaster Class Academy</th>\n",
       "      <th>eXtremegenerationIT</th>\n",
       "      <th>edX</th>\n",
       "      <th>edureka!</th>\n",
       "      <th>freeCodeCamp.org</th>\n",
       "      <th>geekbytes</th>\n",
       "      <th>iKennyHD</th>\n",
       "      <th>iNeuron iNtelligence</th>\n",
       "      <th>iT24Hrs</th>\n",
       "      <th>instituto cpfl</th>\n",
       "      <th>inzva team</th>\n",
       "      <th>jpmorgan</th>\n",
       "      <th>lakshay aggarwal</th>\n",
       "      <th>miracl6</th>\n",
       "      <th>nETSETOS</th>\n",
       "      <th>nejimakijima</th>\n",
       "      <th>njan</th>\n",
       "      <th>outcompete</th>\n",
       "      <th>pyGuru</th>\n",
       "      <th>sentdex</th>\n",
       "      <th>stanfordonline</th>\n",
       "      <th>stanley kan</th>\n",
       "      <th>study mart</th>\n",
       "      <th>suthichai live</th>\n",
       "      <th>teacher4u</th>\n",
       "      <th>techninja betechnical</th>\n",
       "      <th>upGrad</th>\n",
       "      <th>uΔΔTube</th>\n",
       "      <th>vcubingx</th>\n",
       "      <th>vectoroad</th>\n",
       "      <th>veryacademy</th>\n",
       "      <th>{‘フーテンのグラさん’:‘ジェントルふじふじ’}</th>\n",
       "      <th>АйТиБорода</th>\n",
       "      <th>Продюсер будущего</th>\n",
       "      <th>Флесс</th>\n",
       "      <th>أكاديمية الفهرية Al-Fihriya Academy</th>\n",
       "      <th>へちやぼらけ・データサイエンティスト</th>\n",
       "      <th>エンジニアを目指すSESチャンネル</th>\n",
       "      <th>元専業Kaggler カレーちゃん</th>\n",
       "      <th>渡邉裕亮</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0-Introduction-Module3: Deep Learning and AI ...</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title       date  views  \\\n",
       "0  S0-Introduction-Module3: Deep Learning and AI ... 2020-08-25     22   \n",
       "\n",
       "   1littlecoder  365 Data Science  :CodeWebsDuh :  A.I.M Learning  AI Coding  \\\n",
       "0             0                 0               0               0          0   \n",
       "\n",
       "   AI Learner hub  AI era  AICamp  AIPRA  AP2V Academy  ASQStatsDivision  \\\n",
       "0               0       0       0      0             0                 0   \n",
       "\n",
       "   AWS Online Tech Talks  Aakash N S  Abacus AI  Abhishek Agarrwal  \\\n",
       "0                      0           0          0                  0   \n",
       "\n",
       "   Abhishek Thakur  Abuzar Ghaffari  Academind  Accenture  \\\n",
       "0                0                0          0          0   \n",
       "\n",
       "   Accenture in the Philippines  Acsia Technologies  Adriano Gianini  \\\n",
       "0                             0                   0                0   \n",
       "\n",
       "   Adriano Marcos Rodrigues Figueiredo  Adventures in the Cloud  \\\n",
       "0                                    0                        0   \n",
       "\n",
       "   Affiliate World Conferences  Ahmed Nour  Akash Dash  Albert Coronado  \\\n",
       "0                            0           0           0                0   \n",
       "\n",
       "   Alberto Olla  Alex The Analyst  Alexander Amini  \\\n",
       "0             0                 0                0   \n",
       "\n",
       "   Algoritma Data Science School  Ali Nemati  All About GATE Exam  Alteryx  \\\n",
       "0                              0           0                    0        0   \n",
       "\n",
       "   AltexSoft  Alura Cursos Online  AmandaLovesToAudit  Amanpour and Company  \\\n",
       "0          0                    0                   0                     0   \n",
       "\n",
       "   Amarpreet Singh  Amaze Lab  Amazon Web Services  Amod Sachintha  \\\n",
       "0                0          0                    0               0   \n",
       "\n",
       "   Analytics India Magazine  Analytics Vidhya  Andrew Schonfeld  \\\n",
       "0                         0                 0                 0   \n",
       "\n",
       "   Andrey Sozykin  André Furchner  Andy Jake  Aniedi Udo-Obong  \\\n",
       "0               0               0          0                 0   \n",
       "\n",
       "   Applied AI Course  Art of Engineer  Artificial Intelligence Tutorials  \\\n",
       "0                  0                0                                  0   \n",
       "\n",
       "   Arvind Kumawat  Ashutoshh Singh  Ashvin Nair  Association Quantum  \\\n",
       "0               0                0            0                    0   \n",
       "\n",
       "   Association for Computing Machinery (ACM)  Asumsi  AtomsTalk  \\\n",
       "0                                          0       0          0   \n",
       "\n",
       "   Australian Institute for Machine Learning  \\\n",
       "0                                          0   \n",
       "\n",
       "   BEPEC - Career Transition Simplified  ...  Whirldata  WhiteHatHacking  \\\n",
       "0                                     0  ...          0                0   \n",
       "\n",
       "   Wikitechy  XCTEQ Limited  Xuming Wang  YANGCOM Korea  Yanjun Qi  \\\n",
       "0          0              0            0              0          1   \n",
       "\n",
       "   Yannic Kilcher  Yudi J  Yury Kashnitsky  Zach Star  ZaranTech  \\\n",
       "0               0       0                0          0          0   \n",
       "\n",
       "   Zeeshan Usmani  a ydobon  akshay shekkari  ankitrathi.com  anıl Kaynar  \\\n",
       "0               0         0                0               0            0   \n",
       "\n",
       "   ashish pondit  bespokeDS  biostatistique  codebasics  danny iskandar  \\\n",
       "0              0          0               0           0               0   \n",
       "\n",
       "   datasciencearth  deeplizard  e-tube KTU by jasmin  eMaster Class Academy  \\\n",
       "0                0           0                     0                      0   \n",
       "\n",
       "   eXtremegenerationIT  edX  edureka!  freeCodeCamp.org  geekbytes  iKennyHD  \\\n",
       "0                    0    0         0                 0          0         0   \n",
       "\n",
       "   iNeuron iNtelligence  iT24Hrs  instituto cpfl  inzva team  jpmorgan  \\\n",
       "0                     0        0               0           0         0   \n",
       "\n",
       "   lakshay aggarwal  miracl6  nETSETOS  nejimakijima  njan  outcompete  \\\n",
       "0                 0        0         0             0     0           0   \n",
       "\n",
       "   pyGuru  sentdex  stanfordonline  stanley kan  study mart  suthichai live  \\\n",
       "0       0        0               0            0           0               0   \n",
       "\n",
       "   teacher4u  techninja betechnical  upGrad  uΔΔTube  vcubingx  vectoroad  \\\n",
       "0          0                      0       0        0         0          0   \n",
       "\n",
       "   veryacademy  {‘フーテンのグラさん’:‘ジェントルふじふじ’}  АйТиБорода  Продюсер будущего  \\\n",
       "0            0                          0           0                  0   \n",
       "\n",
       "   Флесс  أكاديمية الفهرية Al-Fihriya Academy  へちやぼらけ・データサイエンティスト  \\\n",
       "0      0                                    0                   0   \n",
       "\n",
       "   エンジニアを目指すSESチャンネル  元専業Kaggler カレーちゃん  渡邉裕亮  \n",
       "0                  0                  0     0  \n",
       "\n",
       "[1 rows x 643 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-a8f173a545ec>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[uploader] = df_limpo[uploader]\n"
     ]
    }
   ],
   "source": [
    "for uploader in df_limpo.drop(['title', 'date', 'views'], axis=1).columns:\n",
    "    features[uploader] = df_limpo[uploader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((714, 642), (696, 642), (714,), (696,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < '2020-03-10'\n",
    "mask_val = df_limpo['date'] >= '2020-03-10'\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 642)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[mask_train].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((714, 642), (696, 642), (714,), (696,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < '2020-03-10'\n",
    "mask_val = df_limpo['date'] >= '2020-03-10'\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train = df_limpo[mask_train]['title']\n",
    "title_val = df_limpo[mask_val]['title']\n",
    "\n",
    "# Min df - minimo de vezes que palavra tem que aparecer pra virar coluna\n",
    "title_vec = TfidfVectorizer(min_df=2, ngram_range=(1,2))\n",
    "\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 1134)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando as variávels numéricas com as geradas pelo TfidfVectorizer\n",
    "Xtrain_wtitle = sparse.hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = sparse.hstack([Xval, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((714, 1776), (696, 1776))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle.shape, Xval_wtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 1776)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=4,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_rf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=1, random_state=0, class_weight='balanced', n_jobs=4)\n",
    "mdl_rf.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf = mdl_rf.predict_proba(Xval_wtitle)[: ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39605472026665745, 0.683620535448095)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O resultado pode ter dado diferente peplo random_state\n",
    "average_precision_score(yval, p_rf), roc_auc_score(yval, p_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF\n",
    "#  (0.39545173300116343, 0.6776220857432473)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhavel/miniconda3/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "params = [0.003924937303997735,\n",
    " 10,\n",
    " 9,\n",
    " 0.42896739513988846,\n",
    " 0.08080324515701484,\n",
    " 196,\n",
    " 1,\n",
    " 5]\n",
    "\n",
    "lr = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "\n",
    "min_df = params[6]\n",
    "ngram_range = (1, params[7])\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)\n",
    "\n",
    "Xtrain_wtitle = sparse.hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = sparse.hstack([Xval, title_bow_val])\n",
    "\n",
    "mdl_lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                     min_child_samples=min_child_samples, subsample=subsample,\n",
    "                     colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                     class_weight=\"balanced\", n_jobs=6)\n",
    "mdl_lgbm.fit(Xtrain_wtitle, ytrain)\n",
    "\n",
    "p_lgbm = mdl_lgbm.predict_proba(Xval_wtitle)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39010753360298556, 0.6728221334446366)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p_lgbm), roc_auc_score(yval, p_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM HTuned\n",
    "# (0.39010753360298556, 0.6728221334446366)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Logistic Reg\n",
    "\n",
    "Usamos `makepipeline` para aplicar o scaler e em seguida o modelo, em sequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('maxabsscaler', MaxAbsScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.5, n_jobs=6, random_state=0))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle2 = csr_matrix(Xtrain_wtitle.copy())\n",
    "Xval_wtitle2 = csr_matrix(Xval_wtitle.copy())\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MaxAbsScaler()\n",
    "\n",
    "#Xtrain_wtitle2[:, :2] = scaler.fit_transform(Xtrain_wtitle2[:, :2].todense())\n",
    "#Xval_wtitle2[:, :2] = scaler.transform(Xval_wtitle2[:, :2].todense())\n",
    "#Xtrain_wtitle2 = scaler.fit_transform(Xtrain_wtitle2)\n",
    "#Xval_wtitle2 = scaler.transform(Xval_wtitle2)\n",
    "\n",
    "lr_pipeline = make_pipeline(MaxAbsScaler(), LogisticRegression(C=0.5, penalty='l2',n_jobs=6, random_state=0))\n",
    "lr_pipeline.fit(Xtrain_wtitle2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lr = lr_pipeline.predict_proba(Xval_wtitle2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4295233599530305, 0.671194323534673)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p_lr), roc_auc_score(yval, p_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic\n",
    "# (0.4295233599530305, 0.671194323534673)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.3969764593456903, 0.677681712479876) RF  \n",
    "(0.4120975561037116, 0.677729413869179) LGBM  \n",
    "(0.4176249062603176, 0.6702999224852424)LR  \n",
    "\n",
    "(0.4050885250264036, 0.6983244887007335)LGBM NGRAM 2.3\n",
    "\n",
    "````\n",
    "# RAFAEL\n",
    "# RDF\n",
    "#  (0.39545173300116343, 0.6776220857432473)\n",
    "# LightGBM HTuned\n",
    "# (0.39010753360298556, 0.6728221334446366)\n",
    "# Logistic\n",
    "# (0.4295233599530305, 0.671194323534673)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43406392130802807, 0.6988253532884146)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (p_lr + p_rf + p_lgbm)/3\n",
    "average_precision_score(yval, p), roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Corr\n",
    "\n",
    "LightGBM tem pouco com Logistic e RandomForest, indicando asism que eles preve de forma bem diferente os dados entre si. ENtao usando juntos, é sinal que via ter ganho, pois um vai puxar pra cima onde o outro nao puxaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734372</td>\n",
       "      <td>0.531961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.734372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.531961</td>\n",
       "      <td>0.629294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR        RF      LGBM\n",
       "LR    1.000000  0.734372  0.531961\n",
       "RF    0.734372  1.000000  0.629294\n",
       "LGBM  0.531961  0.629294  1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"LR\": p_lr, \"RF\": p_rf, \"LGBM\": p_lgbm}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4427779169972088, 0.6897978653628287)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tentao apenas 2 deles\n",
    "p = 0.5*p_lgbm + 0.5*p_lr\n",
    "average_precision_score(yval, p), roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAFAEL - BEST SCORE\n",
    "# (0.4427779169972088, 0.6897978653628287) 0.5/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF\n",
    "#  (0.39545173300116343, 0.6776220857432473)\n",
    "# LightGBM HTuned\n",
    "# (0.39010753360298556, 0.6728221334446366)\n",
    "# Logistic\n",
    "# (0.4295233599530305, 0.671194323534673)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Salvar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title_vectorizer_2021-12-11.pkl.z']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(mdl_lgbm, \"lgbm_2021-12-11.pkl.z\")\n",
    "jb.dump(lr_pipeline, \"logistic_reg_2021-12-11.pkl.z\")\n",
    "#jb.dump(lr_pipeline, \"logistic_reg_20200208.pkl.z\")\n",
    "jb.dump(title_vec, \"title_vectorizer_2021-12-11.pkl.z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "Fizemos mas nâo testamos em test. Train/Test.\n",
    "\n",
    "O mais interressante é por o mdoelo em produçâo o mais ceo possível e de lá testar se a solução está valendo ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CESAR EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_20200911 = open('lgbm_20200911', 'wb')\n",
    "pickle.dump(mdl_lgbm, lgbm_20200911)\n",
    "lgbm_20200911.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_20200911 = open('random_forest_20200911', 'wb')\n",
    "pickle.dump(mdl_rf, random_forest_20200911)\n",
    "random_forest_20200911.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectorizer_20200911 = open('title_vectorizer_20200911', 'wb')\n",
    "pickle.dump(title_vec, title_vectorizer_20200911)\n",
    "title_vectorizer_20200911.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title_vectorizer_20200911.pkl.z']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(mdl_lgbm, \"lgbm_20200911.pkl.z\")\n",
    "jb.dump(mdl_rf, \"random_forest_20200911.pkl.z\")\n",
    "#jb.dump(lr_pipeline, \"logistic_reg_20200911.pkl.z\")\n",
    "jb.dump(title_vec, \"title_vectorizer_20200911.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_rf = pickle.load( open( \"random_forest_20200911\", \"rb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
